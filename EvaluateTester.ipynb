{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c891687-b516-4e0a-beb1-c84187b70e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebkumar/repos/stanford/project/odqa-experiments/odqa-experiments/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import time\n",
    "\n",
    "from overlap_evaluate import read_references, read_annotations, ANNOTATIONS, _print_score\n",
    "\n",
    "from evaluate import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a302ec9-3053-4b19-b327-df95941f9273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebkumar/repos/stanford/project/odqa-experiments/odqa-experiments/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c547f39d-18d8-466f-b4d0-1875a1231a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/t5-large-ssm-nq\"\n",
    "\n",
    "# t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-large-ssm-nq\")\n",
    "# t5_tok = AutoTokenizer.from_pretrained(\"google/t5-large-ssm-nq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a79e75-3ec9-404f-8be2-e44cc1a7bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tok = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b933769c-63cd-4612-9de3-59cc018ba329",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d4afa-3f0a-44ae-b0af-e962f4af8d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73803a22-c79e-4984-a777-2196cab5253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google/t5-11b-ssm-tqa\n",
    "# google/t5-large-ssm-nq\n",
    "# google/t5-11b-ssm-wq\n",
    "\n",
    "# google/t5-xxl-ssm-wq\n",
    "\n",
    "class T5QA(QAModel):\n",
    "    t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    t5_tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def predict_answer(self, question: str) -> str:\n",
    "        input_ids = self.t5_tok(question, return_tensors=\"pt\").input_ids\n",
    "        gen_output = self.t5_qa_model.generate(input_ids)[0]\n",
    "        prediction = self.t5_tok.decode(gen_output, skip_special_tokens=True)\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37701d29-40ba-4334-9bb2-cccf5bc00a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5QA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2425cf2f-16b9-47f4-9fd5-132fba7a5dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At example: 40 after 35.389 seconds. Expecting to take: 0.8847 more minutes\n",
      "At example: 80 after 68.256 seconds. Expecting to take: 0.2844 more minutes\n",
      "--------------------------------------------------\n",
      "Label : total\n",
      "N examples  :  100\n",
      "Exact Match :  28.0\n",
      "Bert Score :  NA\n",
      "Meteor Score :  0.29355768830660717\n",
      "--------------------------------------------------\n",
      "Label : question_overlap\n",
      "N examples  :  6\n",
      "Exact Match :  83.33333333333333\n",
      "Bert Score :  NA\n",
      "Meteor Score :  0.6276041666666666\n",
      "--------------------------------------------------\n",
      "Label : no_question_overlap\n",
      "N examples  :  16\n",
      "Exact Match :  12.5\n",
      "Bert Score :  NA\n",
      "Meteor Score :  0.18622398176263308\n",
      "--------------------------------------------------\n",
      "Label : answer_overlap\n",
      "N examples  :  58\n",
      "Exact Match :  46.55172413793103\n",
      "Bert Score :  NA\n",
      "Meteor Score :  0.4470926942370762\n",
      "--------------------------------------------------\n",
      "Label : no_answer_overlap\n",
      "N examples  :  42\n",
      "Exact Match :  2.380952380952381\n",
      "Bert Score :  NA\n",
      "Meteor Score :  0.08153315630738808\n",
      "--------------------------------------------------\n",
      "Label : answer_overlap_only\n",
      "N examples  :  6\n",
      "Exact Match :  16.666666666666668\n",
      "Bert Score :  NA\n",
      "Meteor Score :  0.24961263557754787\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(nrows=100, get_new_predictions=True, dataset=QADataset.nq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80bd6e-7a3e-45fa-a48e-a4f484479dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odqa-experiments",
   "language": "python",
   "name": "odqa-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
