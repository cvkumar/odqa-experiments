{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c891687-b516-4e0a-beb1-c84187b70e03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebkumar/repos/stanford/project/odqa-experiments/odqa-experiments/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import time\n",
    "\n",
    "from overlap_evaluate import read_references, read_annotations, ANNOTATIONS, _print_score\n",
    "\n",
    "from evaluate import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c547f39d-18d8-466f-b4d0-1875a1231a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/t5-xl-ssm-nq\"\n",
    "# model_name = \"google/t5-large-ssm-nq\"\n",
    "\n",
    "# t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-large-ssm-nq\")\n",
    "# t5_tok = AutoTokenizer.from_pretrained(\"google/t5-large-ssm-nq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a79e75-3ec9-404f-8be2-e44cc1a7bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73803a22-c79e-4984-a777-2196cab5253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleQA(QAModel):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def predict_answer(self, question: str, contexts: list) -> str:\n",
    "        input_ids = self.tokenizer(question, return_tensors=\"pt\").input_ids\n",
    "        gen_output = self.model.generate(input_ids)[0]\n",
    "        prediction = self.tokenizer.decode(gen_output, skip_special_tokens=True)\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37701d29-40ba-4334-9bb2-cccf5bc00a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SampleQA(dataset=QADataset.nq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5a02b-bcc4-428e-8591-63a504cb229a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67cd955-e87c-4bdf-8117-03e0f918e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 3610 predictions\n",
      "At example: 40 after 108.706 seconds. Expecting to take: 161.7002 more minutes\n",
      "At example: 80 after 212.465 seconds. Expecting to take: 156.2503 more minutes\n",
      "At example: 120 after 319.34 seconds. Expecting to take: 154.7912 more minutes\n",
      "At example: 160 after 427.823 seconds. Expecting to take: 153.7489 more minutes\n",
      "At example: 200 after 527.089 seconds. Expecting to take: 149.7811 more minutes\n",
      "At example: 240 after 634.91 seconds. Expecting to take: 148.5866 more minutes\n",
      "At example: 280 after 780.187 seconds. Expecting to take: 154.6442 more minutes\n",
      "At example: 320 after 1026.825 seconds. Expecting to take: 175.9507 more minutes\n",
      "At example: 360 after 1247.56 seconds. Expecting to take: 187.7116 more minutes\n",
      "At example: 400 after 1469.877 seconds. Expecting to take: 196.596 more minutes\n",
      "At example: 440 after 1723.213 seconds. Expecting to take: 206.9161 more minutes\n",
      "At example: 480 after 1975.257 seconds. Expecting to take: 214.672 more minutes\n",
      "At example: 520 after 2221.055 seconds. Expecting to take: 219.9699 more minutes\n",
      "At example: 560 after 2467.609 seconds. Expecting to take: 223.9943 more minutes\n",
      "At example: 600 after 2642.346 seconds. Expecting to take: 220.9295 more minutes\n",
      "At example: 640 after 2791.837 seconds. Expecting to take: 215.9311 more minutes\n",
      "At example: 680 after 3032.076 seconds. Expecting to take: 217.7447 more minutes\n",
      "At example: 720 after 3292.317 seconds. Expecting to take: 220.2499 more minutes\n",
      "At example: 760 after 3545.003 seconds. Expecting to take: 221.5627 more minutes\n",
      "At example: 800 after 3784.956 seconds. Expecting to take: 221.5776 more minutes\n",
      "At example: 840 after 3980.555 seconds. Expecting to take: 218.7726 more minutes\n",
      "At example: 880 after 4230.498 seconds. Expecting to take: 218.736 more minutes\n",
      "At example: 920 after 4492.183 seconds. Expecting to take: 218.9125 more minutes\n",
      "At example: 960 after 4731.385 seconds. Expecting to take: 217.6766 more minutes\n",
      "At example: 1000 after 4998.762 seconds. Expecting to take: 217.4461 more minutes\n",
      "At example: 1040 after 5201.182 seconds. Expecting to take: 214.2153 more minutes\n",
      "At example: 1080 after 5392.714 seconds. Expecting to take: 210.5489 more minutes\n",
      "At example: 1120 after 5550.471 seconds. Expecting to take: 205.6648 more minutes\n",
      "At example: 1160 after 5795.805 seconds. Expecting to take: 204.019 more minutes\n",
      "At example: 1200 after 6041.516 seconds. Expecting to take: 202.223 more minutes\n",
      "At example: 1240 after 6294.524 seconds. Expecting to take: 200.511 more minutes\n",
      "At example: 1280 after 6489.854 seconds. Expecting to take: 196.8927 more minutes\n",
      "At example: 1320 after 6736.846 seconds. Expecting to take: 194.7901 more minutes\n",
      "At example: 1360 after 6971.86 seconds. Expecting to take: 192.2388 more minutes\n",
      "At example: 1400 after 7206.027 seconds. Expecting to take: 189.5871 more minutes\n",
      "At example: 1440 after 7455.311 seconds. Expecting to take: 187.2457 more minutes\n",
      "At example: 1480 after 7628.751 seconds. Expecting to take: 182.9869 more minutes\n",
      "At example: 1520 after 7774.311 seconds. Expecting to take: 178.1613 more minutes\n",
      "At example: 1560 after 7984.954 seconds. Expecting to take: 174.8841 more minutes\n",
      "At example: 1600 after 8235.159 seconds. Expecting to take: 172.4236 more minutes\n",
      "At example: 1640 after 8490.811 seconds. Expecting to take: 169.9888 more minutes\n",
      "At example: 1680 after 8719.895 seconds. Expecting to take: 166.9583 more minutes\n",
      "At example: 1720 after 8895.531 seconds. Expecting to take: 162.9123 more minutes\n",
      "At example: 1760 after 8999.405 seconds. Expecting to take: 157.66 more minutes\n",
      "At example: 1800 after 9101.455 seconds. Expecting to take: 152.5336 more minutes\n",
      "At example: 1840 after 9205.959 seconds. Expecting to take: 147.5955 more minutes\n",
      "At example: 1880 after 9309.754 seconds. Expecting to take: 142.7826 more minutes\n",
      "At example: 1920 after 9408.391 seconds. Expecting to take: 138.0224 more minutes\n",
      "At example: 1960 after 9546.064 seconds. Expecting to take: 133.9371 more minutes\n",
      "At example: 2000 after 9796.879 seconds. Expecting to take: 131.4415 more minutes\n",
      "At example: 2040 after 9904.277 seconds. Expecting to take: 127.0402 more minutes\n",
      "At example: 2080 after 10004.869 seconds. Expecting to take: 122.6558 more minutes\n",
      "At example: 2120 after 10100.489 seconds. Expecting to take: 118.3155 more minutes\n",
      "At example: 2160 after 10204.023 seconds. Expecting to take: 114.1654 more minutes\n",
      "At example: 2200 after 10303.686 seconds. Expecting to take: 110.0621 more minutes\n",
      "At example: 2240 after 10402.863 seconds. Expecting to take: 106.0411 more minutes\n",
      "At example: 2280 after 10512.22 seconds. Expecting to take: 102.2021 more minutes\n",
      "At example: 2320 after 10614.584 seconds. Expecting to take: 98.3679 more minutes\n",
      "At example: 2360 after 10718.513 seconds. Expecting to take: 94.6196 more minutes\n",
      "At example: 2400 after 10827.967 seconds. Expecting to take: 90.985 more minutes\n",
      "At example: 2440 after 10927.421 seconds. Expecting to take: 87.3298 more minutes\n",
      "At example: 2480 after 11023.992 seconds. Expecting to take: 83.7171 more minutes\n",
      "At example: 2520 after 11125.076 seconds. Expecting to take: 80.2006 more minutes\n",
      "At example: 2560 after 11229.079 seconds. Expecting to take: 76.7613 more minutes\n",
      "At example: 2600 after 11336.708 seconds. Expecting to take: 73.3979 more minutes\n",
      "At example: 2640 after 11437.832 seconds. Expecting to take: 70.0423 more minutes\n",
      "At example: 2680 after 11540.289 seconds. Expecting to take: 66.7442 more minutes\n",
      "At example: 2720 after 11645.499 seconds. Expecting to take: 63.5079 more minutes\n",
      "At example: 2760 after 11749.559 seconds. Expecting to take: 60.3087 more minutes\n",
      "At example: 2800 after 11848.186 seconds. Expecting to take: 57.1252 more minutes\n",
      "At example: 2840 after 11948.842 seconds. Expecting to take: 53.9942 more minutes\n",
      "At example: 2880 after 12059.164 seconds. Expecting to take: 50.9444 more minutes\n",
      "At example: 2920 after 12155.262 seconds. Expecting to take: 47.8718 more minutes\n",
      "At example: 2960 after 12262.918 seconds. Expecting to take: 44.8812 more minutes\n",
      "At example: 3000 after 12369.518 seconds. Expecting to take: 41.9189 more minutes\n",
      "At example: 3040 after 12477.144 seconds. Expecting to take: 38.9911 more minutes\n",
      "At example: 3080 after 12583.174 seconds. Expecting to take: 36.0881 more minutes\n",
      "At example: 3120 after 12690.982 seconds. Expecting to take: 33.2189 more minutes\n",
      "At example: 3160 after 12803.797 seconds. Expecting to take: 30.3888 more minutes\n",
      "At example: 3200 after 12910.359 seconds. Expecting to take: 27.569 more minutes\n",
      "At example: 3240 after 13015.158 seconds. Expecting to take: 24.7716 more minutes\n",
      "At example: 3280 after 13121.935 seconds. Expecting to take: 22.0032 more minutes\n",
      "At example: 3320 after 13222.677 seconds. Expecting to take: 19.2499 more minutes\n",
      "At example: 3360 after 13324.796 seconds. Expecting to take: 16.5238 more minutes\n",
      "At example: 3400 after 13426.873 seconds. Expecting to take: 13.8218 more minutes\n",
      "At example: 3440 after 13531.594 seconds. Expecting to take: 11.1452 more minutes\n",
      "At example: 3480 after 13633.581 seconds. Expecting to take: 8.4883 more minutes\n",
      "At example: 3520 after 13737.272 seconds. Expecting to take: 5.854 more minutes\n",
      "At example: 3560 after 13843.656 seconds. Expecting to take: 3.2406 more minutes\n",
      "At example: 3600 after 13949.194 seconds. Expecting to take: 0.6458 more minutes\n"
     ]
    }
   ],
   "source": [
    "predictions = model.get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425cf2f-16b9-47f4-9fd5-132fba7a5dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining scores:\n",
      "\n",
      "Scoring annotation label: total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "saved_results, label_scores = model.evaluate(get_bert_score=True, get_predictions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5719e26-5382-45f3-b333-0b3264c971be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac2adf-3296-461e-90dc-f6db4f84a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(saved_results)\n",
    "\n",
    "df.to_csv(f\"results/nq/t5-xl-ssm-nq_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa0e1a-aec5-4e6c-a2be-32977cdacfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"results/nq/t5-xl-ssm-nq_results.json\", \"w\") as outfile:\n",
    "    json.dump(label_scores, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd7b442-5ae3-4497-a37b-faa710a26786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(f\"results/nq/t5-large-ssm-nq_results.csv\").to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8aa7bf-3870-499a-8c88-f4ccbd25b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e5597e0-6d22-4c25-8496-d3ba8cc0ed9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'em': 0.0224,\n",
       " 'f1': 0.075,\n",
       " 'bert_score': 0.2455,\n",
       " 'meteor_score': 0.0573,\n",
       " 'total': 357}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compute_no_overlap_score(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "186df6de-2ff2-4ad2-8709-3028f0935553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'em': 0.1333,\n",
       " 'f1': 0.1977,\n",
       " 'bert_score': 0.4635,\n",
       " 'meteor_score': 0.1645,\n",
       " 'total': 315}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compute_answer_overlap_only_scores(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998dbf4e-52e2-4ae5-a8e4-9dc5d8422eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BigBirdForQuestionAnswering\n",
    "\n",
    "# model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\")\n",
    "\n",
    "# question = \"How many days are in a year?\"\n",
    "# context = \"There are 365 days in a year.\"\n",
    "# encoded_input = tokenizer(question, context, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "\n",
    "# tokenizer.decode(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odqa-experiments",
   "language": "python",
   "name": "odqa-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
